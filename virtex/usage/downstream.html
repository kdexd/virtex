<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-120523111-2"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-120523111-2');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Inconsolata&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Ubuntu+Mono&display=swap" rel="stylesheet">


  <title>How to evaluate on downstream tasks? &mdash; virtex 1.4 documentation</title>

      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/clipboard.min.js"></script>
        <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="virtex.config" href="../config.html" />
    <link rel="prev" title="How to train your VirTex model?" href="pretrain.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> virtex
          </a>
              <div class="version">
                1.4
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="setup_dependencies.html">How to setup this codebase?</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_zoo.html">VirTex Model Zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="pretrain.html">How to train your VirTex model?</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">How to evaluate on downstream tasks?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#pascal-voc-2007-linear-classification">PASCAL VOC 2007 Linear Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="#imagenet-linear-classification">ImageNet Linear Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="#instance-segmentation-and-object-detection-on-coco">Instance Segmentation (and Object Detection) on COCO</a></li>
<li class="toctree-l2"><a class="reference internal" href="#instance-segmentation-on-lvis">Instance Segmentation on LVIS</a></li>
<li class="toctree-l2"><a class="reference internal" href="#object-detection-on-pascal-voc-2007-12">Object Detection on PASCAL VOC 2007+12</a></li>
<li class="toctree-l2"><a class="reference internal" href="#inaturalist-2018-fine-grained-classification">iNaturalist 2018 Fine-Grained Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="#image-captioning-on-coco-captions-val2017">Image Captioning on COCO Captions val2017</a></li>
<li class="toctree-l2"><a class="reference internal" href="#running-image-captioning-inference-on-arbitrary-images">Running Image Captioning Inference on Arbitrary Images</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../config.html">virtex.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../factories.html">virtex.factories</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data.html">virtex.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models.html">virtex.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules.html">virtex.modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optim.html">virtex.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils.html">virtex.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_zoo.html">virtex.model_zoo</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">virtex</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>How to evaluate on downstream tasks?</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/virtex/usage/downstream.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="how-to-evaluate-on-downstream-tasks">
<h1>How to evaluate on downstream tasks?<a class="headerlink" href="#how-to-evaluate-on-downstream-tasks" title="Permalink to this headline"></a></h1>
<p>In our paper, we evaluate our pretrained VirTex models on seven different
downstream tasks. Our codebase supports all of these evaluations. Throughout
this documentation, we consider a specific example of our VirTex pretrained
model being evaluated for ensuring filepath uniformity in the following example
command snippets. Paths can be trivially adjusted for any other VirTex model;
evaluating the baselines (MoCo, ImageNet-supervised, Random Init) require
additional changes in commands, explained in the last sub-section.</p>
<p>As an example, consider a pretraining job for our best performing VirTex model
(<code class="docutils literal notranslate"><span class="pre">width_ablations/bicaptioning_R_50_L1_H2048.yaml</span></code>). The serialization
directory might look something like this:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>/tmp/bicaptioning_R_50_L1_H2048
    pretrain_config.yaml
    log-rank0.txt    # stdout/stderr per GPU process
    log-rank1.txt
    ...
    log-rank7.txt
    checkpoint_2000.pth
    checkpoint_4000.pth
    ...
    checkpoint_498000.pth
    checkpoint_500000.pth    # serialized checkpoints
    train_captioning_forward/
        events.out.* ...    # tensorboard logs
    ...
</pre></div>
</div>
<p>We evaluate all checkpoints on <strong>PASCAL VOC 2007 Linear Classification</strong>, and
then evaluate the best checkpoint (here, it was iteration 500000) on all other
downstream tasks.</p>
<section id="pascal-voc-2007-linear-classification">
<h2>PASCAL VOC 2007 Linear Classification<a class="headerlink" href="#pascal-voc-2007-linear-classification" title="Permalink to this headline"></a></h2>
<p>Evaluate a single VirTex pretrained checkpoint on VOC 2007 <code class="docutils literal notranslate"><span class="pre">trainval</span></code> split:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python scripts/clf_voc07.py <span class="se">\</span>
    --config /tmp/bicaptioning_R_50_L1_H2048/pretrain_config.yaml <span class="se">\</span>
    --down-config configs/downstream/voc07_clf.yaml <span class="se">\</span>
    --checkpoint-path /tmp/bicaptioning_R_50_L1_H2048/checkpoint_500000.pth <span class="se">\</span>
    --weight-init virtex <span class="se">\</span>
    --num-gpus-per-machine <span class="m">1</span> <span class="se">\</span>
    --cpu-workers <span class="m">4</span> <span class="se">\</span>
    --serialization-dir /tmp/bicaptioning_R_50_L1_H2048
</pre></div>
</div>
<p>To evaluate recent 100 checkpoints in the sub-directory, this command can be
looped over as follows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="o">((</span><span class="nv">iter</span> <span class="o">=</span> <span class="m">300000</span><span class="p">;</span> iter &lt;<span class="o">=</span> <span class="m">500000</span><span class="p">;</span> <span class="nv">iter</span><span class="o">+=</span><span class="m">2000</span><span class="o">))</span><span class="p">;</span> <span class="k">do</span>
    <span class="c1"># add command with `checkpoint_$iter.pth`</span>
<span class="k">done</span>
</pre></div>
</div>
<p>This script write metric to tensorboard logs in the same pretraining directory,
all VOC07 mAP curves appear together with pretraining loss curves.</p>
</section>
<hr class="docutils" />
<section id="imagenet-linear-classification">
<h2>ImageNet Linear Classification<a class="headerlink" href="#imagenet-linear-classification" title="Permalink to this headline"></a></h2>
<p>We train a linear classifier on 2048-dimensional global average pooled features
extracted from a frozen visual backbone. Evaluate a checkpoint (for example,
iteration 500000) on this task as:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python scripts/clf_linear.py <span class="se">\</span>
    --config /tmp/bicaptioning_R_50_L1_H2048/pretrain_config.yaml <span class="se">\</span>
    --down-config configs/downstream/imagenet_clf.yaml <span class="se">\</span>
    --checkpoint-path /tmp/bicaptioning_R_50_L1_H2048/checkpoint_500000.pth <span class="se">\</span>
    --weight-init virtex <span class="se">\</span>
    --num-gpus-per-machine <span class="m">8</span> <span class="se">\</span>
    --cpu-workers <span class="m">4</span> <span class="se">\</span>
    --serialization-dir /tmp/bicaptioning_R_50_L1_H2048/imagenet_500000 <span class="se">\</span>
    --checkpoint-every <span class="m">5005</span>  <span class="c1"># 1 epoch of ImageNet</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="instance-segmentation-and-object-detection-on-coco">
<h2>Instance Segmentation (and Object Detection) on COCO<a class="headerlink" href="#instance-segmentation-and-object-detection-on-coco" title="Permalink to this headline"></a></h2>
<p>Train a Mask R-CNN with FPN backbone for COCO Instance Segmentation (and Object
Detection, because it also has a box head) by initializing the backbone from
VirTex pretrained weights:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python scripts/eval_detectron2.py <span class="se">\</span>
    --config /tmp/bicaptioning_R_50_L1_H2048/pretrain_config.yaml <span class="se">\</span>
    --d2-config configs/detectron2/coco_segm_default_init_2x.yaml <span class="se">\</span>
    --checkpoint-path /tmp/bicaptioning_R_50_L1_H2048/checkpoint_500000.pth <span class="se">\</span>
    --weight-init virtex <span class="se">\</span>
    --num-gpus-per-machine <span class="m">8</span> <span class="se">\</span>
    --cpu-workers <span class="m">2</span> <span class="se">\</span>
    --serialization-dir /tmp/bicaptioning_R_50_L1_H2048/coco_segm_500000 <span class="se">\</span>
    --checkpoint-every <span class="m">5000</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ol class="arabic simple">
<li><p>This script periodically serializes checkpoints but skips validation
step during training for saving time; to evaluate a serialized checkpoint
and write results to tensorboard, provide it as <code class="docutils literal notranslate"><span class="pre">--checkpoint-path</span></code> and
additional flags <code class="docutils literal notranslate"><span class="pre">--resume</span> <span class="pre">--eval-only</span></code>.</p></li>
<li><p>Note that <code class="docutils literal notranslate"><span class="pre">--d2-config</span></code> here is in Detectron2 format, and not our
package <a class="reference internal" href="../config.html#virtex.config.Config" title="virtex.config.Config"><code class="xref py py-class docutils literal notranslate"><span class="pre">Config</span></code></a>.</p></li>
</ol>
<p>These points are applicable for all tasks described below.</p>
</div>
</section>
<hr class="docutils" />
<section id="instance-segmentation-on-lvis">
<h2>Instance Segmentation on LVIS<a class="headerlink" href="#instance-segmentation-on-lvis" title="Permalink to this headline"></a></h2>
<p>Train a Mask R-CNN with FPN backbone for LVIS Instance Segmentation by
initializing the backbone from VirTex pretrained weights:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python scripts/eval_detectron2.py <span class="se">\</span>
    --config /tmp/bicaptioning_R_50_L1_H2048/pretrain_config.yaml <span class="se">\</span>
    --d2-config configs/detectron2/lvis_segm_default_init_2x.yaml <span class="se">\</span>
    --checkpoint-path /tmp/bicaptioning_R_50_L1_H2048/checkpoint_500000.pth <span class="se">\</span>
    --weight-init virtex <span class="se">\</span>
    --num-gpus-per-machine <span class="m">8</span> <span class="se">\</span>
    --cpu-workers <span class="m">2</span> <span class="se">\</span>
    --serialization-dir /tmp/bicaptioning_R_50_L1_H2048/lvis_segm_500000 <span class="se">\</span>
    --checkpoint-every <span class="m">5000</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="object-detection-on-pascal-voc-2007-12">
<h2>Object Detection on PASCAL VOC 2007+12<a class="headerlink" href="#object-detection-on-pascal-voc-2007-12" title="Permalink to this headline"></a></h2>
<p>Train a Faster R-CNN with C4 backbone for PASCAL VOC 2007+12 Object Detection
by initializing the backbone from VirTex pretrained weights:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python scripts/eval_detectron2.py <span class="se">\</span>
    --config /tmp/bicaptioning_R_50_L1_H2048/pretrain_config.yaml <span class="se">\</span>
    --d2-config configs/detectron2/voc_det_default_init_24k.yaml <span class="se">\</span>
    --checkpoint-path /tmp/bicaptioning_R_50_L1_H2048/checkpoint_500000.pth <span class="se">\</span>
    --weight-init virtex <span class="se">\</span>
    --num-gpus-per-machine <span class="m">8</span> <span class="se">\</span>
    --cpu-workers <span class="m">2</span> <span class="se">\</span>
    --serialization-dir /tmp/bicaptioning_R_50_L1_H2048/voc_det_500000 <span class="se">\</span>
    --checkpoint-every <span class="m">2500</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="inaturalist-2018-fine-grained-classification">
<h2>iNaturalist 2018 Fine-Grained Classification<a class="headerlink" href="#inaturalist-2018-fine-grained-classification" title="Permalink to this headline"></a></h2>
<p>Fine-tune the VirTex pretrained visual backbone end-to-end on iNaturalist 2018
dataset:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python scripts/clf_linear.py <span class="se">\</span>
    --config /tmp/bicaptioning_R_50_L1_H2048/pretrain_config.yaml <span class="se">\</span>
    --down-config configs/downstream/inaturalist_clf.yaml <span class="se">\</span>
    --checkpoint-path /tmp/bicaptioning_R_50_L1_H2048/checkpoint_500000.pth <span class="se">\</span>
    --weight-init virtex <span class="se">\</span>
    --num-gpus-per-machine <span class="m">8</span> <span class="se">\</span>
    --cpu-workers <span class="m">4</span> <span class="se">\</span>
    --serialization-dir /tmp/bicaptioning_R_50_L1_H2048/inaturalist_500000 <span class="se">\</span>
    --checkpoint-every <span class="m">1710</span>  <span class="c1"># 1 epoch of iNaturalist</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="image-captioning-on-coco-captions-val2017">
<h2>Image Captioning on COCO Captions val2017<a class="headerlink" href="#image-captioning-on-coco-captions-val2017" title="Permalink to this headline"></a></h2>
<p>Evaluate a pretrained VirTex model on image captioning for COCO Captions val2017
split (reporting CIDEr and SPICE metics):</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python scripts/eval_captioning.py <span class="se">\</span>
    --config /tmp/bicaptioning_R_50_L1_H2048/pretrain_config.yaml <span class="se">\</span>
    --checkpoint-path /tmp/bicaptioning_R_50_L1_H2048/checkpoint_500000.pth <span class="se">\</span>
    --calc-metrics <span class="se">\</span>
    --num-gpus-per-machine <span class="m">1</span> <span class="se">\</span>
    --cpu-workers <span class="m">4</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="running-image-captioning-inference-on-arbitrary-images">
<h2>Running Image Captioning Inference on Arbitrary Images<a class="headerlink" href="#running-image-captioning-inference-on-arbitrary-images" title="Permalink to this headline"></a></h2>
<p>The above script can be used for generating captions for any images in a directory.
Replace certain commands as follows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python scripts/eval_captioning.py <span class="se">\</span>
    --config /tmp/bicaptioning_R_50_L1_H2048/pretrain_config.yaml <span class="se">\</span>
    --checkpoint-path /tmp/bicaptioning_R_50_L1_H2048/checkpoint_500000.pth <span class="se">\</span>
    --data-root /path/to/images_dir <span class="se">\</span>
    --output /path/to/save/predictions.json <span class="se">\</span>
    --num-gpus-per-machine <span class="m">1</span> <span class="se">\</span>
    --cpu-workers <span class="m">4</span>
</pre></div>
</div>
<p>This script will save predictions in JSON format. Since our goal is to not
improve image captioning, these models may not generate the best captions.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="pretrain.html" class="btn btn-neutral float-left" title="How to train your VirTex model?" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../config.html" class="btn btn-neutral float-right" title="virtex.config" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Karan Desai and Justin Johnson.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>